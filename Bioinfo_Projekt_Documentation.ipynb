{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinfo Projekt Gruppe 4-4: k-means \n",
    "*Members: Benedict, Julia, Thorge and Marilena*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Implement the following algorithms in python using the numpy library:\n",
    "\n",
    "1. implement k-means:\n",
    "\n",
    "1. compare your implementation with the sklearn implementation with respect to quality and speed\n",
    "  implement mini-batch k-means:\n",
    "\n",
    "1. compare your implementation with the sklearn implementation with respect to quality and speed\n",
    "  implement k-means++ initialization:\n",
    "\n",
    "1. Compare the runtime and quality of your k-means implementation and your mini batch k-means implementation for  different datasets. You can use code from sklearn to generate datasets of arbitrary size and difficulty  (https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py). You should generate multiple plots to visualize the comparison (eg. you can plot the runtinme / cluster quality for different dataset sizes / number of clusters)\n",
    "\n",
    "1. Cluster the 3K PBMCs from a Healthy Donor Dataset from 10x Genomics\n",
    "1. use scanpy to load the data ( see https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html)\n",
    "1. compare the performance of your implementations with the sklearn implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all a few packages are imported that were used throughout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from statistics import mean\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request as url\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import csv\n",
    "from sklearn.base import BaseEstimator, ClusterMixin, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class Kmeans() is based on the sklearn variant.  \n",
    "It takes following arguments:  \n",
    "     **inits** --> initialisations  \n",
    "     Standard = 10    \n",
    "        **.k** --> number of clusters  \n",
    "        Standard = 8  \n",
    "    **maxit** --> maximum iterations.  \n",
    "    Standard = 300  \n",
    "    **method** --> method of choosing starting clusters.  \n",
    "    Standard = \"++\". Option = \"rng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans(BaseEstimator, ClusterMixin, TransformerMixin):               # Input: processed dataset, Output: clustered data (kmeans, kmeans++)\n",
    "    def __init__(self, inits=10, k=8, maxit=300, method=\"++\"):\n",
    "        \n",
    "        self.labels_ = None\n",
    "        self.cluster_centers_ = None\n",
    "        self._inits = inits\n",
    "        self._k = k\n",
    "        self._maxit = maxit\n",
    "        self._method = method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit method:\n",
    "\n",
    "fits the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self,data):\n",
    "        self._data = data\n",
    "        best_clust = float('inf')\n",
    "        \n",
    "        for i in (range(self._inits)):\n",
    "            dot = np.random.choice(range(len(self._data)), self._k, replace=False)\n",
    "            self.cluster_centers_ = self._data[dot]\n",
    "            for i in range(self._maxit):\n",
    "                clusters = np.expand_dims(self.cluster_centers_, axis=1)\n",
    "                data = np.expand_dims(self._data, axis=0)\n",
    "                eucl = np.linalg.norm(clusters-data, axis=2) # euclidean dist by using integrated numpy function\n",
    "                self.labels_ = np.argmin(eucl, axis = 0)\n",
    "                for i in range(self._k): # range of clusters\n",
    "                    position = np.where(self.labels_ == i) # position im array bestimmen und dann die entspechenden punkte aus data auslesen\n",
    "                    self.cluster_centers_[i] = self._data[position].mean(axis = 0)\n",
    "                    #out = pd.DataFrame(data[np.argwhere(dist == i)].squeeze())\n",
    "                overall_quality = np.sum(np.min(eucl.T, axis=1))\n",
    "                if overall_quality < best_clust:\n",
    "                    best_clust = overall_quality\n",
    "                    best_dist = self.labels_\n",
    "                    best_centers = self.cluster_centers_\n",
    "            self.cluster_centers_ = best_centers\n",
    "            self.labels_ = best_dist\n",
    "                \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now expanded by kmeans++  \n",
    "set argument: method=\"++\" (by default as in sklearn)\n",
    "\n",
    "    Instead of all centroids only the first is appended by random choice.\n",
    "\n",
    "__The remaining k-1 centroids are chosen as followed:__ \n",
    "\n",
    "**1.** Calculate squared distance D of every point to its clostest centroid  \n",
    "**2.** Every point is assigned a probability to be chosen as the next centroid according to:\n",
    "\n",
    "$$D(x)\\over \\sum^{}_{x\\in X} D(x)$$  \n",
    "\n",
    "**3.** New centroid is picked from all datapoints considering their assigned probabilities  \n",
    "**4.** Repeat steps 1-3 until k centroids are chosen\n",
    "\n",
    "    Note: This method only provides intial centroids and does not change the clustering process for the following iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            if self._method == \"rng\": # random centers are choosen\n",
    "                #print(\"rng\")\n",
    "                dot = np.random.choice(range(len(self._data)), self._k, replace=False)\n",
    "                self.cluster_centers_ = self._data[dot]\n",
    "            elif self._method == \"++\": # kmeans++ is initiated\n",
    "                #print(\"++\")\n",
    "                dot = np.random.choice(len(self._data), replace=False) # random startpunkt\n",
    "                clusters = np.array([self._data[dot]])\n",
    "                pointer = np.array([])\n",
    "                for i in range (self._k-1):\n",
    "                    D = np.array([])\n",
    "            \n",
    "                    for j in range (len(self._data)):\n",
    "                        D = np.append(D,np.min(np.sum((self._data[j]-clusters)**2, axis = 1)))\n",
    "                \n",
    "                    pointer = np.append(pointer, D, axis = 0) \n",
    "            \n",
    "                    p = D/np.sum(D)\n",
    "                    cummulative_p = np.cumsum(p)\n",
    "            \n",
    "                    r = random.random()\n",
    "                    ind = np.where(cummulative_p >= r)[0][0]\n",
    "            \n",
    "                    clusters = np.append(clusters,[self._data[ind]], axis = 0)\n",
    "                self.cluster_centers_ = clusters\n",
    "            else:\n",
    "                raise AttributeError(\"No valid method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict method:\n",
    "used to predict which point depends to a certain cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "        clusters = np.expand_dims(self.cluster_centers_, axis=1)\n",
    "        data = np.expand_dims(X, axis=0)\n",
    "        eucl = np.linalg.norm(clusters-data, axis=2) # euclidean dist by using integrated numpy function\n",
    "        self.labels_ = np.argmin(eucl, axis = 0)\n",
    "        return self.labels_ #returns the cluster with minimum distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transform method\n",
    "\n",
    "transforms data to cluster-distance space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(self, X):\n",
    "        clusters = np.expand_dims(self.cluster_centers_, axis=1)\n",
    "        data = np.expand_dims(X, axis=0)\n",
    "        eucl = np.linalg.norm(clusters-data, axis=2)\n",
    "        return eucl.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class MiniBatch Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
